Group: cd-007
Chen Hao Zhang 999272228
Tianrui Xiao 999018049

Run command:
1) make
2) ./compiler467 -Tn -R trace.out -E error.out test_input

Check trace output

Running with -T enables the tracing functionality, n/p/x specifies tracing for scanner/parser/program execution. 
The -R tracefile flag allows the user to specify an output for the trace, and -E errorfile allows the errors to be dumped.


Token Generation
The design of tokens was fairly straightforward, and Chenhao was responsible for the more difficult task of 
designing the correct regular expressions for tokens, in particular the int and float value tokens.
Tianrui was primarily responsible for declaring the tokens in the parser.y file and implementing safety checks 
on data types the scanner encounters, including checking for type overflow and identifiers exceeding 32 chars.
Overflow/underflow is detected based on comparison with the values scanned and INT_MAX or INT_MIN.
Tianrui and Chenhao created the test_input file that have some purposely failing test cases in the scanner.

The scanner will store valid values scanned in the union yylval, to allow for easy access, including 
int value, float value, and identifier length.

The scanner works by finite state automaton. Token are represented as a number of states, and matching a token means reaching the final state.
In the case of ambiguity, the scanner will match the longest match.
For example: "while123", the scanner will match "while123" as an identifier, as oppose to matching the while keyword and an int iteral.

Reglar expression used for matching tokens is defined by a set of "alphabet": Epsilon, Symbol, Alteration, Concatenation, Repetition.
Regular expression in lex is made easy by syntaxical sugar.
For example: [0-9] defines a digit, and more complex regular expressions are built using simple ones.
